# -*- coding: utf-8 -*-
"""SRCNN vs EDSR training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-A3UHjZyNZNhmodw6cZ4gXwa-AA-_pLb
"""

!pip install torch torchvision matplotlib

import os
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt

class DIV2KDataset(Dataset):
    def __init__(self, lr_dir, hr_dir, transform_lr=None, transform_hr=None):
        self.lr_dir = lr_dir  # Path to the Low-Resolution images directory
        self.hr_dir = hr_dir  # Path to the High-Resolution images directory
        self.lr_images = sorted(os.listdir(lr_dir))  # List and sort LR image files
        self.hr_images = sorted(os.listdir(hr_dir))  # List and sort HR image files
        self.transform_lr = transform_lr  # Transformation for LR images
        self.transform_hr = transform_hr  # Transformation for HR images

    def __len__(self):
        return len(self.lr_images)  # Total number of LR (or HR) images

    def __getitem__(self, idx):
        # Load image paths
        lr_path = os.path.join(self.lr_dir, self.lr_images[idx])
        hr_path = os.path.join(self.hr_dir, self.hr_images[idx])

        # Open images and convert to RGB
        lr_image = Image.open(lr_path).convert("RGB")
        hr_image = Image.open(hr_path).convert("RGB")

        # Apply transformations
        if self.transform_lr:
            lr_image = self.transform_lr(lr_image)
        if self.transform_hr:
            hr_image = self.transform_hr(hr_image)

        return lr_image, hr_image

transform_lr = transforms.Compose([
    transforms.ToTensor(),  # Convert LR images to PyTorch tensors
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]
])

transform_hr = transforms.Compose([
    transforms.ToTensor(),  # Convert HR images to PyTorch tensors
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]
])

!pip install --upgrade google-cloud-storage

from google.colab import auth
auth.authenticate_user()

from google.cloud import storage

# Initialize the Google Cloud Storage client
client = storage.Client()

# Define the bucket name and dataset path
bucket_name = 'gandataset'  # Replace with your actual bucket name
bucket = client.get_bucket(bucket_name)

# List files in the 'gandataset' folder
blobs = bucket.list_blobs(prefix='gandataset/')
for blob in blobs:
    print(blob.name)

import os

# Define local paths for downloading
local_dataset_path = './Dataset'
os.makedirs(local_dataset_path, exist_ok=True)

# Download all files from the storage bucket
for blob in bucket.list_blobs(prefix='gandataset/'):
    # Define local file path
    local_file_path = os.path.join(local_dataset_path, blob.name.split('/')[-1])
    if not blob.name.endswith('/'):  # Skip directories
        print(f"Downloading {blob.name} to {local_file_path}...")
        blob.download_to_filename(local_file_path)

print("Files downloaded:")
print(os.listdir(local_dataset_path))

from google.cloud import storage

# Initialize the Google Cloud Storage client
client = storage.Client()

# Define the bucket name
bucket_name = 'gandataset'  # Your bucket name
bucket = client.get_bucket(bucket_name)

# List all files in the bucket
print("Listing all files in the bucket:")
blobs = bucket.list_blobs()  # No prefix
for blob in blobs:
    print(blob.name)  # Print file paths

import os

# Define local dataset directory
local_dataset_path = './Dataset'

# Create the base directory for the dataset
os.makedirs(local_dataset_path, exist_ok=True)

# Download files from the bucket
print("Downloading files...")
blobs = bucket.list_blobs()  # List all files in the bucket

for blob in blobs:
    if not blob.name.endswith('/'):  # Skip folders (GCP stores folders as virtual paths)
        # Recreate folder structure in the local path
        local_file_path = os.path.join(local_dataset_path, blob.name)
        os.makedirs(os.path.dirname(local_file_path), exist_ok=True)

        # Download the file
        print(f"Downloading {blob.name} to {local_file_path}...")
        blob.download_to_filename(local_file_path)

print("Download completed!")

# List the downloaded folders and files
for root, dirs, files in os.walk(local_dataset_path):
    print(f"Directory: {root}")
    for file in files[:10]:  # Show only the first 10 files for brevity
        print(f"  File: {file}")



# Training paths
train_lr_x4_path = './Dataset/DIV2K_train_LR_bicubic_X4/X4'
train_lr_x2_path = './Dataset/DIV2K_train_LR_bicubic/X2'
train_hr_path = './Dataset/DIV2K_train_HR'

# Validation paths
valid_lr_x4_path = './Dataset/DIV2K_valid_LR_bicubic_X4/X4'
valid_lr_x2_path = './Dataset/DIV2K_valid_LR_bicubic/X2'
valid_hr_path = './Dataset/DIV2K_valid_HR'

print("Train LR X4 Path:", train_lr_x4_path)
print("Train HR Path:", train_hr_path)
print("Valid LR X4 Path:", valid_lr_x4_path)
print("Valid HR Path:", valid_hr_path)

# Test dataset loading
train_dataset = DIV2KDataset(train_lr_x4_path, train_hr_path, transform_lr=transform_lr, transform_hr=transform_hr)
print(f"Number of samples in training dataset (X4): {len(train_dataset)}")

valid_dataset = DIV2KDataset(valid_lr_x4_path, valid_hr_path, transform_lr=transform_lr, transform_hr=transform_hr)
print(f"Number of samples in validation dataset (X4): {len(valid_dataset)}")

# Visualize a few training samples
import matplotlib.pyplot as plt

for i in range(3):  # Show 3 samples
    lr_image, hr_image = train_dataset[i]

    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    plt.imshow(lr_image.permute(1, 2, 0).numpy() * 0.5 + 0.5)  # Convert [-1, 1] to [0, 1]
    plt.title(f"Low-Resolution (X4) Image {i+1}")

    plt.subplot(1, 2, 2)
    plt.imshow(hr_image.permute(1, 2, 0).numpy() * 0.5 + 0.5)  # Convert [-1, 1] to [0, 1]
    plt.title(f"High-Resolution Image {i+1}")
    plt.show()

"""**SRCNN Model** - Super-Resolution Convolutional Neural Network"""

import torch
import torch.nn as nn

class SRCNN(nn.Module):
    def __init__(self):
        super(SRCNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=9, padding=4)
        self.relu = nn.ReLU()
        self.conv2 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=5, padding=2)
        self.conv3 = nn.Conv2d(in_channels=32, out_channels=3, kernel_size=5, padding=2)

    def forward(self, x):
        x = self.relu(self.conv1(x))
        x = self.relu(self.conv2(x))
        x = self.conv3(x)
        return x

# Instantiate the model
model = SRCNN()
print(model)

"""**setting up loss function,optimizer and hyperparameters**"""

# Define Loss Function and Optimizer
criterion = nn.MSELoss()  # Mean Squared Error Loss
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# Hyperparameters
num_epochs = 10
batch_size = 16

"""**Define the training loop**"""

import os
from PIL import Image
from torch.utils.data import Dataset

class DIV2KDataset(Dataset):
    def __init__(self, lr_dir, hr_dir, transform_lr=None, transform_hr=None):
        self.lr_dir = lr_dir
        self.hr_dir = hr_dir
        self.lr_images = sorted(os.listdir(lr_dir))
        self.hr_images = sorted(os.listdir(hr_dir))
        self.transform_lr = transform_lr
        self.transform_hr = transform_hr

    def __len__(self):
        return len(self.lr_images)

    def __getitem__(self, idx):
        # Load images
        lr_path = os.path.join(self.lr_dir, self.lr_images[idx])
        hr_path = os.path.join(self.hr_dir, self.hr_images[idx])

        lr_image = Image.open(lr_path).convert("RGB")
        hr_image = Image.open(hr_path).convert("RGB")

        # Apply transformations
        if self.transform_lr:
            lr_image = self.transform_lr(lr_image)
        if self.transform_hr:
            hr_image = self.transform_hr(hr_image)

        return lr_image, hr_image

from torchvision import transforms

transform_lr = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]
])

transform_hr = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]
])

train_lr_x4_path = './Dataset/DIV2K_train_LR_bicubic_X4/X4'
train_hr_path = './Dataset/DIV2K_train_HR'
valid_lr_x4_path = './Dataset/DIV2K_valid_LR_bicubic_X4/X4'
valid_hr_path = './Dataset/DIV2K_valid_HR'

from torch.utils.data import DataLoader

# Define transformations (if not already defined)
transform_lr = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

transform_hr = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# Create datasets
train_dataset = DIV2KDataset(
    lr_dir=train_lr_x4_path,
    hr_dir=train_hr_path,
    transform_lr=transform_lr,
    transform_hr=transform_hr
)

valid_dataset = DIV2KDataset(
    lr_dir=valid_lr_x4_path,
    hr_dir=valid_hr_path,
    transform_lr=transform_lr,
    transform_hr=transform_hr
)

# Check the number of samples
print(f"Number of training samples: {len(train_dataset)}")
print(f"Number of validation samples: {len(valid_dataset)}")

from torch.utils.data import DataLoader

# Set batch size
batch_size = 16

# Create dataloaders
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)

print(f"Training batches: {len(train_dataloader)}")
print(f"Validation batches: {len(valid_dataloader)}")

import torch.nn as nn

class BasicSuperResolutionModel(nn.Module):
    def __init__(self):
        super(BasicSuperResolutionModel, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)
        self.conv3 = nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1)

    def forward(self, x):
        x = self.relu(self.conv1(x))
        x = self.relu(self.conv2(x))
        x = self.conv3(x)
        return x

import torch.optim as optim

# Define device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Initialize model, loss, and optimizer
model = BasicSuperResolutionModel().to(device)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

from torchvision import transforms

# Define the fixed resolution (example: 128x128)
fixed_size = (128, 128)

transform_lr = transforms.Compose([
    transforms.Resize(fixed_size),  # Resize to fixed size
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]
])

transform_hr = transforms.Compose([
    transforms.Resize(fixed_size),  # Resize to fixed size
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]
])

train_dataset = DIV2KDataset(
    lr_dir=train_lr_x4_path,
    hr_dir=train_hr_path,
    transform_lr=transform_lr,
    transform_hr=transform_hr
)

valid_dataset = DIV2KDataset(
    lr_dir=valid_lr_x4_path,
    hr_dir=valid_hr_path,
    transform_lr=transform_lr,
    transform_hr=transform_hr
)

train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)

for lr_images, hr_images in train_dataloader:
    print(f"Low-Resolution Image Batch Shape: {lr_images.shape}")
    print(f"High-Resolution Image Batch Shape: {hr_images.shape}")
    break

# Training loop
num_epochs = 10

for epoch in range(num_epochs):
    print(f"Epoch {epoch+1}/{num_epochs}")
    model.train()
    epoch_loss = 0

    for lr_images, hr_images in tqdm(train_dataloader):
        # Move data to device
        lr_images = lr_images.to(device)
        hr_images = hr_images.to(device)

        # Forward pass
        optimizer.zero_grad()
        outputs = model(lr_images)
        loss = criterion(outputs, hr_images)

        # Backward pass and optimization
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()

    print(f"Training Loss: {epoch_loss / len(train_dataloader)}")

    # Validation step
    model.eval()
    with torch.no_grad():
        val_loss = 0
        for lr_images, hr_images in valid_dataloader:
            lr_images = lr_images.to(device)
            hr_images = hr_images.to(device)

            outputs = model(lr_images)
            loss = criterion(outputs, hr_images)
            val_loss += loss.item()

        print(f"Validation Loss: {val_loss / len(valid_dataloader)}")

import matplotlib.pyplot as plt

# Get a sample from the validation set
model.eval()
with torch.no_grad():
    lr_sample, hr_sample = valid_dataset[0]
    lr_sample = lr_sample.unsqueeze(0).to(device)  # Add batch dimension
    output = model(lr_sample).squeeze(0).cpu()  # Remove batch dimension

    # Unnormalize images
    lr_sample = (lr_sample.squeeze(0).cpu() * 0.5 + 0.5).permute(1, 2, 0).numpy()
    hr_sample = (hr_sample * 0.5 + 0.5).permute(1, 2, 0).numpy()
    output = (output * 0.5 + 0.5).permute(1, 2, 0).numpy()

    # Plot images
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 3, 1)
    plt.title("Low-Resolution")
    plt.imshow(lr_sample)
    plt.subplot(1, 3, 2)
    plt.title("High-Resolution (Ground Truth)")
    plt.imshow(hr_sample)
    plt.subplot(1, 3, 3)
    plt.title("Super-Resolved Output")
    plt.imshow(output)
    plt.show()

import matplotlib.pyplot as plt

# Visualize a few validation samples
model.eval()
with torch.no_grad():
    for i in range(3):  # Visualize 3 samples
        lr_image, hr_image = valid_dataset[i]
        lr_image = lr_image.unsqueeze(0).to(device)  # Add batch dimension
        output = model(lr_image).squeeze(0).cpu()  # Remove batch dimension

        # Unnormalize images
        lr_image = (lr_image.squeeze(0).cpu() * 0.5 + 0.5).permute(1, 2, 0).numpy()
        hr_image = (hr_image * 0.5 + 0.5).permute(1, 2, 0).numpy()
        output = (output * 0.5 + 0.5).permute(1, 2, 0).numpy()

        # Plot images
        plt.figure(figsize=(12, 4))
        plt.subplot(1, 3, 1)
        plt.title("Low-Resolution")
        plt.imshow(lr_image)
        plt.subplot(1, 3, 2)
        plt.title("High-Resolution (Ground Truth)")
        plt.imshow(hr_image)
        plt.subplot(1, 3, 3)
        plt.title("Super-Resolved Output")
        plt.imshow(output)
        plt.show()

torch.save(model.state_dict(), "super_resolution_model.pth")
print("Model saved successfully.")

"""**EDSR (Enhanced Deep Super-Resolution Network) Model**"""

!pip install scikit-image google-cloud-storage

from google.colab import auth
auth.authenticate_user()

from google.cloud import storage
client = storage.Client()
bucket = client.bucket('gandataset')  # Replace with your bucket name

from google.colab import files
files.upload()  # This will allow you to upload your JSON key file

import os

# Replace 'your-key-file.json' with the name of your uploaded JSON key
#os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'plenary-office-441617-a4-fdb28f0f97bb.json'

from google.cloud import storage

# Initialize the storage client
client = storage.Client()

# Access your bucket
bucket = client.get_bucket('gandataset')  # Replace with your bucket name

def download_gcs_files(bucket, prefix, local_dir):
    blobs = bucket.list_blobs(prefix=prefix)  # List all files in the given prefix
    for blob in blobs:
        file_name = os.path.basename(blob.name)
        if not file_name:  # Skip directories
            continue

        # Create local directory and file path
        file_path = os.path.join(local_dir, file_name)
        os.makedirs(os.path.dirname(file_path), exist_ok=True)

        # Download the file
        blob.download_to_filename(file_path)
        print(f"Downloaded {blob.name} to {file_path}")

# Download the files
download_gcs_files(bucket, "DIV2K_train_LR_bicubic_X4/X4/", "./Dataset/DIV2K_train_LR_bicubic_X4/X4/")
download_gcs_files(bucket, "DIV2K_train_HR/", "./Dataset/DIV2K_train_HR/")
download_gcs_files(bucket, "DIV2K_valid_LR_bicubic_X4/X4/", "./Dataset/DIV2K_valid_LR_bicubic_X4/X4/")
download_gcs_files(bucket, "DIV2K_valid_HR/", "./Dataset/DIV2K_valid_HR/")

import os

print("Train LR Path Exists:", os.path.exists('./Dataset/DIV2K_train_LR_bicubic_X4/X4'))
print("Train HR Path Exists:", os.path.exists('./Dataset/DIV2K_train_HR'))
print("Valid LR Path Exists:", os.path.exists('./Dataset/DIV2K_valid_LR_bicubic_X4/X4'))
print("Valid HR Path Exists:", os.path.exists('./Dataset/DIV2K_valid_HR'))

import torch
import torch.nn as nn

# Define the Residual Block for EDSR
class ResidualBlock(nn.Module):
    def __init__(self, n_features):
        super(ResidualBlock, self).__init__()
        self.block = nn.Sequential(
            nn.Conv2d(n_features, n_features, kernel_size=3, padding=1, bias=False),
            nn.ReLU(inplace=True),
            nn.Conv2d(n_features, n_features, kernel_size=3, padding=1, bias=False)
        )

    def forward(self, x):
        return x + self.block(x)  # Skip connection

# Define the EDSR Model
class EDSR(nn.Module):
    def __init__(self, scale_factor=4, n_residuals=16, n_features=64):
        super(EDSR, self).__init__()

        # Initial Convolution Layer
        self.head = nn.Conv2d(3, n_features, kernel_size=3, padding=1, bias=False)

        # Residual Blocks
        self.body = nn.Sequential(
            *[ResidualBlock(n_features) for _ in range(n_residuals)],
            nn.Conv2d(n_features, n_features, kernel_size=3, padding=1, bias=False)
        )

        # Upsampling Layer
        self.tail = nn.Sequential(
            nn.Conv2d(n_features, n_features * (scale_factor ** 2), kernel_size=3, padding=1),
            nn.PixelShuffle(scale_factor),
            nn.Conv2d(n_features, 3, kernel_size=3, padding=1)
        )

    def forward(self, x):
        x = self.head(x)
        res = self.body(x)
        x = x + res  # Long skip connection
        x = self.tail(x)
        return x

from torch.utils.data import Dataset
from PIL import Image
import os

class DIV2KDataset(Dataset):
    def __init__(self, lr_dir, hr_dir, transform_lr=None, transform_hr=None):
        self.lr_dir = lr_dir
        self.hr_dir = hr_dir
        self.lr_images = sorted(os.listdir(lr_dir))
        self.hr_images = sorted(os.listdir(hr_dir))
        self.transform_lr = transform_lr
        self.transform_hr = transform_hr

    def __len__(self):
        return len(self.lr_images)

    def __getitem__(self, idx):
        lr_path = os.path.join(self.lr_dir, self.lr_images[idx])
        hr_path = os.path.join(self.hr_dir, self.hr_images[idx])

        lr_image = Image.open(lr_path)
        hr_image = Image.open(hr_path)

        if self.transform_lr:
            lr_image = self.transform_lr(lr_image)
        if self.transform_hr:
            hr_image = self.transform_hr(hr_image)

        return lr_image, hr_image

from torchvision.transforms import Compose, Resize, ToTensor

transform_lr = Compose([
    Resize((128, 128)),  # LR images remain 128x128
    ToTensor()
])

transform_hr = Compose([
    Resize((512, 512)),  # HR images resized to 512x512
    ToTensor()
])

train_dataset = DIV2KDataset(
    "./Dataset/DIV2K_train_LR_bicubic_X4/X4",
    "./Dataset/DIV2K_train_HR",
    transform_lr=transform_lr,
    transform_hr=transform_hr
)

valid_dataset = DIV2KDataset(
    "./Dataset/DIV2K_valid_LR_bicubic_X4/X4",
    "./Dataset/DIV2K_valid_HR",
    transform_lr=transform_lr,
    transform_hr=transform_hr
)

from torch.utils.data import DataLoader

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)

for lr_images, hr_images in train_loader:
    print("Low-Resolution Image Shape:", lr_images.shape)  # Expected: [16, 3, 128, 128]
    print("High-Resolution Image Shape:", hr_images.shape)  # Expected: [16, 3, 512, 512]
    break

print(num_epochs)

num_epoches2 = 10

import torch
import torch.nn as nn

# Define the Residual Block
class ResidualBlock(nn.Module):
    def __init__(self, n_features):
        super(ResidualBlock, self).__init__()
        self.block = nn.Sequential(
            nn.Conv2d(n_features, n_features, kernel_size=3, padding=1, bias=False),
            nn.ReLU(inplace=True),
            nn.Conv2d(n_features, n_features, kernel_size=3, padding=1, bias=False)
        )

    def forward(self, x):
        return x + self.block(x)  # Skip connection

# Define the EDSR Model
class EDSR(nn.Module):
    def __init__(self, scale_factor=4, n_residuals=16, n_features=64):
        super(EDSR, self).__init__()

        # Initial Convolution Layer
        self.head = nn.Conv2d(3, n_features, kernel_size=3, padding=1, bias=False)

        # Residual Blocks
        self.body = nn.Sequential(
            *[ResidualBlock(n_features) for _ in range(n_residuals)],
            nn.Conv2d(n_features, n_features, kernel_size=3, padding=1, bias=False)
        )

        # Upsampling Layer
        self.tail = nn.Sequential(
            nn.Conv2d(n_features, n_features * (scale_factor ** 2), kernel_size=3, padding=1),
            nn.PixelShuffle(scale_factor),
            nn.Conv2d(n_features, 3, kernel_size=3, padding=1)
        )

    def forward(self, x):
        x = self.head(x)
        res = self.body(x)
        x = x + res  # Long skip connection
        x = self.tail(x)
        return x

edsr_model = EDSR(scale_factor=4)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
edsr_model.to(device)

print(edsr_model)  # This should display the architecture of the model

import torch.optim as optim

# Initialize the optimizer
optimizer = optim.Adam(edsr_model.parameters(), lr=1e-4)  # Example learning rate

criterion = nn.MSELoss()

# Define the optimizer and loss function
optimizer = optim.Adam(edsr_model.parameters(), lr=1e-4)
criterion = nn.MSELoss()

# Move the model to the device (if not already done)
edsr_model.to(device)

for epoch in range(num_epoches2):
    edsr_model.train()
    epoch_loss = 0
    for lr_images, hr_images in train_loader:
        lr_images, hr_images = lr_images.to(device), hr_images.to(device)
        optimizer.zero_grad()
        outputs = edsr_model(lr_images)
        loss = criterion(outputs, hr_images)
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()
    print(f"Epoch [{epoch+1}/{num_epoches2}], Loss: {epoch_loss:.4f}")

torch.save(edsr_model.state_dict(), "edsr_trained_model.pth")
print("Model saved as edsr_trained_model.pth")

import matplotlib.pyplot as plt  # Add this line if not already included

edsr_model.eval()
with torch.no_grad():
    for lr_images, hr_images in valid_loader:
        lr_image = lr_images[0].unsqueeze(0).to(device)  # Process the first image in the batch
        hr_image = hr_images[0]  # Get the corresponding high-resolution image
        sr_image = edsr_model(lr_image)

        # Convert tensors to NumPy for visualization
        lr_image_np = lr_image.cpu().squeeze(0).permute(1, 2, 0).numpy()
        sr_image_np = sr_image.cpu().squeeze(0).permute(1, 2, 0).numpy()
        hr_image_np = hr_image.cpu().squeeze(0).permute(1, 2, 0).numpy()

        # Plot the images
        plt.figure(figsize=(15, 5))
        plt.subplot(1, 3, 1)
        plt.title("Low-Resolution")
        plt.imshow(lr_image_np)
        plt.axis("off")

        plt.subplot(1, 3, 2)
        plt.title("Super-Resolved")
        plt.imshow(sr_image_np)
        plt.axis("off")

        plt.subplot(1, 3, 3)
        plt.title("High-Resolution (Ground Truth)")
        plt.imshow(hr_image_np)
        plt.axis("off")

        plt.show()
        break